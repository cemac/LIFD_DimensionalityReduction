{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cemac/LIFD_DimensionalityReduction/blob/main/LIFD_dimensionality_reduction_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDBjgBPAaCjH"
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame # Display YouTube videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T12:37:35.131452Z",
     "iopub.status.busy": "2022-06-15T12:37:35.131014Z",
     "iopub.status.idle": "2022-06-15T12:37:55.67664Z",
     "shell.execute_reply": "2022-06-15T12:37:55.675474Z",
     "shell.execute_reply.started": "2022-06-15T12:37:35.131414Z"
    },
    "id": "KceBOmdOMMQ3"
   },
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "    <h1> Tutorial 7 </h1>\n",
    "    <h2> Dimensionality Reduction </h2>\n",
    "</div>      \n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "This Jupyter notebook is based on Jonathan Coney's work on identifying and characterising trapped lee waves using dimensionality reduction. The work is outlined in [Coney et al., 2023](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.4592). This notebook will go through the basics of [Principal Component Analysis](https://www.billconnelly.net/?p=697) and Dimensionality Reduction methods using some toy code from a Kaggle tutorial and the MNIST dataset, and then apply those methods to an Earth Science application based on Jonathan Coney's work.\n",
    "\n",
    "\n",
    "## The very basics\n",
    "\n",
    "If you are new to neural networks, there is a [toy neural network Python code example](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/tree/main/ToyNeuralNetwork) included in the [LIFD ENV ML Notebooks Repository]( https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS), where we create a two-layer neural network to illustrate the fundamentals of how neural networks work and give equivalent code using the Python machine learning library [Keras](https://keras.io/).\n",
    "\n",
    "\n",
    "## Recommended reading\n",
    "\n",
    "\n",
    "* [All you need to know on Neural Networks](https://suryansh.xyz/articles/nn_aynk)\n",
    "* [Introduction to Neural Networks](https://victorzhou.com/blog/intro-to-neural-networks/)\n",
    "* [Coney, J., Denby, L., Ross, A.N., Wang, H., Vosper, S., van Niekerk, A., et al. (2023) Identifying and characterising trapped lee waves using deep learning techniques. Quarterly Journal of the Royal Meteorological Society, 1â€“19.](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.4592)\n",
    "* [Kaggle PCA tutorial](https://www.kaggle.com/code/vipulgandhi/pca-beginner-s-guide-to-dimensionality-reduction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJWHfz3xMMQ5"
   },
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "    \n",
    "<h1> Machine Learning Theory </h1>\n",
    "\n",
    "# Dimensionality Reduction\n",
    "\n",
    "## The problem\n",
    "\n",
    "Datasets with more features become more complex and the greater the chance we have of simply overfitting our model. Dimension reduction is a possible solution to this by reducing the number of features to make a simpler model. There are a number of methods to do this while still retaining the important information.\n",
    "\n",
    "## The benefits of dimensionality reduction:\n",
    "\n",
    "1. Less irrelevant data to improve accuracy\n",
    "2. Fewer dimensions lead to faster model training\n",
    "3. Fewer dimensions open up a larger number of possible algorithms to work with\n",
    "4. Smaller datasets take up less storage\n",
    "5. Can remove noise\n",
    "6. Can help with plotting as it's easy to visualise 2D space\n",
    "\n",
    "## The main methods of Dimensionality Reduction\n",
    "\n",
    "This is done by feature extraction or feature engineering. Feature extraction can vary from simple projection methods like Principal Component Analysis or via more complex manifold methods like t-SNE.\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uodHXZMLaG79"
   },
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Princial Component Analysis (PCA) works by linearly mapping data to a lower-dimensional space in a way that maximises variance (to preserve information). The new features are orthogonal, i.e. uncorrelated, and are ranked in order of their explained variance. The first principal component explains the most variance in the data, the second the second most and so on.\n",
    "\n",
    "The first part of this tutorial will be to go through the steps of PCA. If you find you need a refresher on your vector calculus, you might find these pages on [determinants](https://www.mathsisfun.com/algebra/matrix-determinant.html) and [eigenvectors](https://www.mathsisfun.com/algebra/eigenvalue.html) helpful!\n",
    "\n",
    "The following two videos from statquest cover the basics of PCA and its relation to dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDuEELUTZmyg"
   },
   "outputs": [],
   "source": [
    "IFrame(\"https://www.youtube.com/embed/FgakZw6K1QQ?si=WSQfwg7Ig2yftWvT\",\"560\", \"315\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXSK6KceaGbL"
   },
   "outputs": [],
   "source": [
    "IFrame(\"https://www.youtube.com/embed/HMOI_lkzW08?si=gMNZlGBn36qZ9lZC\",\"560\", \"315\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTKPfo79bB-a"
   },
   "source": [
    "# Dimension Manifold Methods\n",
    "\n",
    "\n",
    "Dimension reduction isn't confined to just PCA methods: there are also manifold methods. Sometimes, the data might be too complex for projection methods such as linear PCA. Manifold techniques measure how each training instance linearly relates to its nearest neighbors, then it looks for a low-dimensional representation of the training set where these local relationships are best preserved. Here we will look at at Multi-Dimensional Scaling (MDS) and Isometric mapping (Isomap) techniques. Another commonly used technique is Uniform Manifold Approximation and Projection (UMAP) and there is a great explanation of it in [this article](https://shubh-tripathi.medium.com/decrypted-dimensionality-reduction-4064bfecb87f). Note that UMAP often outperforms Isomap.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7PjzQ01RM29"
   },
   "source": [
    "\n",
    "## U-Net and Segmentation\n",
    "\n",
    "The [U-Net](https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/) model architecture is a convolutional neural network that consists of an encoder and a decoder. The encoder extracts features from 2D input images by coarse-graining the input data with increasing depth in the network and compositing learned features. The decoder uses the patterns extracted by the encoder and upsamples the data, so that a prediction can be made for each pixel. In addition, the upsampled data are combined with data from the encoder at the same level (skip-connections). These skip-connections allow the U-Net to retain high spatial fidelity by combining the up-scaled values in the decoder with more spatially dense values from the encoder, as shown in the diagram below.\n",
    "\n",
    "Finally, the head is where the remaining pixelwise learned spatial features are further manipulated through pixelwise transforms to produce predictions per pixel.\n",
    "\n",
    "![Schematic of U Net](https://rmets.onlinelibrary.wiley.com/cms/asset/63d9263f-f5c7-48dc-8ba6-60f19fb6e5a7/qj4592-fig-0004-m.jpg)\n",
    "\n",
    "In this tutorial, we'll be using the pretrained [fastai](https://www.fast.ai/) learner object [Dynamic U-Net](https://www.mdpi.com/2078-2489/11/2/108), a model designed to extract patterns from data. Building the U-Net from scratch will not be covered in this notebook.\n",
    "\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfUQlcc_b6Ky"
   },
   "outputs": [],
   "source": [
    "IFrame(\"https://www.youtube.com/embed/NhdzGfB1q74?si=p8ti5ydxXvqJuABi\",\"560\", \"315\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3T1ImzFMMQ5"
   },
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "# Python\n",
    "    \n",
    "    \n",
    "## [PyTorch](https://pytorch.org/) & [scikit-learn](https://scikit-learn.org/stable/index.html)\n",
    "\n",
    "The two base machine learning libraries used in this tutorial are PyTorch and scikit-learn. scikit-learn is a lightweight machine learning library that can be used for PCA and manifold dimensionality reduction methods, while PyTorch is required for the deep-learning fastai segmentation model referred to in our more complex Earth Science example.\n",
    "\n",
    "\n",
    "## [fastai](https://www.fast.ai/)\n",
    "\n",
    "A library of machine learning tools that allows you to create deep learning models in just a few lines of code. The library come pre-installed on Google Colab, and is easily installed via conda or pip. The library uses the underlying commonality in deep learning tasks broken down into vision, text, tabular or collaborative filtering applications. In all likelihood, there is already a model configured and trained for a very similar application to the one you're looking to do.\n",
    "\n",
    "Read more about fastai [here](https://docs.fast.ai/).\n",
    "\n",
    "For applications used in this tutorial, the [vision fastai tutorial](https://docs.fast.ai/tutorial.vision.html) covers all the methods used here.\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "If you want to run this notebook locally or on a remote service\n",
    "\n",
    "\n",
    "* [running Jupyter notebooks](https://jupyter.readthedocs.io/en/latest/running.html#running)\n",
    "* [installing the required Python environments](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/blob/main/howtorun.md)\n",
    "* [running the Jupyter notebooks locally](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/blob/main/jupyter_notebooks.md)\n",
    "    \n",
    "</div>\n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR2lCmA4MMQ6"
   },
   "source": [
    "<div style=\"background-color: #ffffcc; padding: 10px;\">\n",
    "    \n",
    "<h1> Requirements </h1>\n",
    "\n",
    "These notebooks should run with the following requirements satisfied.\n",
    "\n",
    "<h2> Python Packages: </h2>\n",
    "\n",
    "* Python 3.8\n",
    "* fastai\n",
    "* pytorch\n",
    "* sklearn\n",
    "* albumentations\n",
    "* numpy\n",
    "* pandas\n",
    "* xarray\n",
    "* matplotlib\n",
    "* notebook\n",
    "\n",
    "<h2> Data Requirements</h2>\n",
    "    \n",
    "This notebook refers to some small external datasets and learner objects which are downloaded via bash scripts within the notebooks.\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQZHsRyrMMQ6"
   },
   "source": [
    "**Contents:**\n",
    "\n",
    "1. [Overview and background information](#)\n",
    "2. [Introduction to PCA, and manifold methods](#)\n",
    "3. [Background information to Earth Science application](#)\n",
    "4. [Example locating and classification of trapped lee waves](#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExBFkWj9MMQ6"
   },
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "# Import modules\n",
    "\n",
    "These are all the modules needed during this tutorial.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJ7oZ_AJMMQ7"
   },
   "outputs": [],
   "source": [
    "# Disable warnings for readability (not recommended outside of tutorial setting!)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5fhtQBQMMQ7"
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "# general file system utilites\n",
    "import os\n",
    "import gc\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting utilies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Libraries Fastai, PyTorch and Sklearn\n",
    "import fastai\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import get_files, RandomSplitter\n",
    "from fastai.learner import Learner\n",
    "import albumentations as A\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap, SpectralEmbedding, TSNE\n",
    "from scipy.ndimage import rotate\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn import manifold\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# path finding for windows systems\n",
    "if os.name=='nt':\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAmkmciOCtAG"
   },
   "source": [
    "Load the [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). This example dataset is often used to demonstrate data science techniques such as PCA. It's lightweight, having only 4 features and 150 entries.\n",
    "\n",
    "We'll download the data and take a quick look below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0p94bLPaChbc"
   },
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "#rename columns\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "#drop null\n",
    "iris.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOaL23wtb56N"
   },
   "source": [
    "We can quickly make a scatter plot of petal width against petal length, colouring by species (Setosa in red, Virginica in green and Versicolour in blue). We can clearly see that there are three distinct clusters in the dataset, so this should be a good dataset to demonstrate Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2oid7n3YJly"
   },
   "outputs": [],
   "source": [
    "colour_list = iris['species'].values\n",
    "colour_list = [c.replace('Iris-setosa', 'r') for c in colour_list]\n",
    "colour_list = [c.replace('Iris-virginica', 'g') for c in colour_list]\n",
    "colour_list = [c.replace('Iris-versicolor', 'b') for c in colour_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6exs_mdXB1Z"
   },
   "outputs": [],
   "source": [
    "plt.scatter(iris['petal_length'].values, iris['petal_width'].values, c=colour_list)\n",
    "plt.title('clusters by petal length + width')\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOUkuSyBdc07"
   },
   "source": [
    "If we replace petal width and length with sepal length and width, we can still see the species clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSORIRVedYIN"
   },
   "outputs": [],
   "source": [
    "plt.scatter(iris['sepal_length'].values, iris['sepal_width'].values, c=colour_list)\n",
    "plt.title('clusters by sepal length + width')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRUEiQpaeIBy"
   },
   "source": [
    "This where PCA comes in handy. By eye we can see that both sepal and petal information independently give species information. This will allow us to use all the information and more robustly separate our clusters.\n",
    "\n",
    "We'll start by standardizing our dataset, otherwise larger ranges will dominate over smaller range variables. We'll use scikit-learn's `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUatw3JjCmIo"
   },
   "outputs": [],
   "source": [
    "X = iris[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y = iris.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUf59p6mGBkF"
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvU_-KDBgX2E"
   },
   "source": [
    "## Eigendecomposition\n",
    "\n",
    "The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the \"core\" of a PCA. The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude. In other words, the eigenvalues explain the variance of the data along the new feature axes.\n",
    "\n",
    "### Covariance Matrix\n",
    "\n",
    "The classic approach to PCA is to perform an eigendecomposition of the covariance matrix, which is a matrix where each element represents the covariance between two features. The covariance between two features $X$ and $Y$ is calculated as follows:\n",
    "\n",
    "\n",
    "$$\\mathrm{cov}(X, Y) = \\dfrac{\\sum(x_i - \\bar{x}) (y_i - \\bar{y})}{N-1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9Eaw0KDGDRL"
   },
   "outputs": [],
   "source": [
    "X_mean = np.mean(X, axis=0)\n",
    "# cov_mat = np.cov(X, rowvar=False)\n",
    "cov_mat = (X - X_mean).T.dot(X - X_mean) / (X.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZJ08BpOGDZv"
   },
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIe9-M5EgzW2"
   },
   "source": [
    "\n",
    "## Singular Value Decomposition\n",
    "\n",
    "While the eigendecomposition of the covariance or correlation matrix may be more intuitiuve, most PCA implementations perform a Singular Value Decomposition (SVD) to improve the computational accuracy. So, let us perform an SVD to confirm that the results are indeed the same:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCgbw9PbGDgS"
   },
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(X.T)\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfyRadGghCLN"
   },
   "source": [
    "Note that the eigenvectors are identical to those above up to a multiplicative constant (in this case -1).\n",
    "\n",
    "## Select Principal Components\n",
    "\n",
    "### Sorting Eigenpairs\n",
    "\n",
    "The goal of PCA is to reduce the dimensionality of the original feature space by projecting it onto a smaller subspace, where the eigenvectors will form the axes. However, the eigenvectors only define the directions of the new axes, since they all have the same unit length 1.\n",
    "\n",
    "In order to decide which eigenvector(s) can be dropped without losing too much information, we need to inspect the corresponding eigenvalues. The eigenvectors with the lowest eigenvalues bear the least information about the distribution of the data: those are the ones that can be dropped.\n",
    "\n",
    "The common approach is to rank the eigenvalues from highest to lowest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5rEbBIhGDkt"
   },
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c05Nf4aKhHd0"
   },
   "source": [
    "\n",
    "## Explained Variance\n",
    "\n",
    "After sorting the eigenpairs, the next question is \"how many principal components are we going to choose for our new feature subspace?\" A useful measure is the so-called \"explained variance\", which can be calculated from the eigenvalues. The explained variance tells us how much information (variance) can be attributed to each of the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK-ee6ldGNWP"
   },
   "outputs": [],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "cum_var_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrZESBMvhMMA"
   },
   "source": [
    "We see that the first two principal components together explain more than 95 percent of the total variance.\n",
    "\n",
    "## Projection Matrix\n",
    "\n",
    "The projection matrix is used to transform the input data $X$ onto the new feature subspace. The projection matrix is a matrix of the concatenated top $k$ eigenvectors.\n",
    "\n",
    "Here, we are reducing the 4-dimensional feature space to a 2-dimensional feature subspace, by choosing the \"top 2\" eigenvectors with the highest eigenvalues to construct our 2-dimensional eigenvector matrix .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRMP_2ZfGNqk"
   },
   "outputs": [],
   "source": [
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1),\n",
    "                      eig_pairs[1][1].reshape(4,1)))\n",
    "\n",
    "print('Matrix W:\\n', matrix_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pzBqCeghPGE"
   },
   "source": [
    "##  Projection onto the New Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8s3GPqTGNve"
   },
   "outputs": [],
   "source": [
    "Y = X.dot(matrix_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0ZznZAvGU1g"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), ('blue', 'red', 'green')):\n",
    "        plt.scatter(Y[y==lab, 0], Y[y==lab, 1], label=lab, c=col)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpP0CuPyhT6T"
   },
   "source": [
    "# Using scikit-learn's inbuilt functions!\n",
    "\n",
    "Thankfully, in practice PCA can be performed quickly using an instance of the `PCA` class in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-N2J05GGU5n"
   },
   "outputs": [],
   "source": [
    "sklearn_pca = PCA(n_components=2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)\n",
    "\n",
    "sklearn_pca.explained_variance_ # check eigenvalues are the same as the ones we calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gACFKq0TGU80"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n",
    "                        ('blue', 'red', 'green')):\n",
    "        plt.scatter(Y_sklearn[y==lab, 0],\n",
    "                    Y_sklearn[y==lab, 1],\n",
    "                    label=lab,\n",
    "                    c=col)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Kz_3bmhjRh"
   },
   "source": [
    "Note that the plot appears to be inverted. This is because the sign each principal component is arbitrary. Here the y-axis is scaled by -1.\n",
    "\n",
    "# Manifold Learning\n",
    "\n",
    "We'll use some in-built functions to demonstrate variations of this in 3D with some Manifold Learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wpt0-TrGqJ8"
   },
   "outputs": [],
   "source": [
    "color = LabelEncoder().fit_transform(y)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "n_components = 3\n",
    "n_neighbors = 5\n",
    "\n",
    "#----PCA----------- sklearn implementation\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "Y = pca.fit_transform(X)\n",
    "\n",
    "ax = fig.add_subplot(131, projection='3d')\n",
    "ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "ax.view_init(4, -72)\n",
    "ax.set_title(\"PCA\")\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "\n",
    "ax.axis('tight')\n",
    "#------------------\n",
    "#----MDS----------- sklearn implementation (Stress minimization-majorization algorithm SMACOF)\n",
    "\n",
    "mds = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
    "Y = mds.fit_transform(X)\n",
    "\n",
    "ax = fig.add_subplot(132, projection='3d')\n",
    "ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "ax.view_init(4, -72)\n",
    "ax.set_title(\"MDS\")\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "\n",
    "ax.axis('tight')\n",
    "#------------------\n",
    "#----Isomap-------- sklearn implementation (with kernel PCA)\n",
    "\n",
    "Y = manifold.Isomap(n_neighbors=n_neighbors,n_components=n_components).fit_transform(X)\n",
    "\n",
    "ax = fig.add_subplot(133, projection='3d')\n",
    "ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "ax.view_init(4, -72)\n",
    "ax.set_title(\"Isomap\")\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "\n",
    "ax.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pfo5F8rAh1yl"
   },
   "source": [
    "Now for the second part of the tutorial we'll use these techniques to go over an applied example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M78dr9ucclFs"
   },
   "source": [
    "<hr>\n",
    "\n",
    "# Background for application to Earth Sciences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKCow81WOJhO"
   },
   "source": [
    "To give you an example of a real research application in Earth Sciences, we'll follow through the steps of how dimensionality reduction was used to identify and characterise\n",
    "\n",
    "# Gravity Waves\n",
    "\n",
    "A gravity wave is a vertical wave, for example a ripple, in the atmosphere. Gravity waves can be formed when air is forced upwards by topography (e.g. wind blowing over a mountain). This creates turbulance that can be felt throughout the column of air above a mountain. Gravity waves are of interest for improving our understanding and forecasting capability, e.g. for aviation. If you'd like to learn more, NOAA have a useful information page all about gravity waves in the atmosphere [here](https://www.weather.gov/source/zhu/ZHU_Training_Page/Miscellaneous/gravity_wave/gravity_wave.html).\n",
    "\n",
    "![diagram of gravity waves](https://www.weather.gov/source/zhu/ZHU_Training_Page/Miscellaneous/gravity_wave/radarscope2.png)\n",
    "(taken from https://www.weather.gov/source/zhu/ZHU_Training_Page/Miscellaneous/gravity_wave/gravity_wave.html)\n",
    "\n",
    "Lee waves can be observed by eye as you get clouds forming on the crest of the wave, e.g. when you look up and see stripes of clouds or lenticular clouds like the image seen below, where a mountain has forced a wave in the air to form. These can be spotted in photos and satellite images. For more information, the Met Office have a basic overview [here](https://www.metoffice.gov.uk/weather/learn-about/weather/types-of-weather/wind/lee-waves).\n",
    "\n",
    "![Lenticular cloud over mountains image](https://www.metoffice.gov.uk/binaries/content/gallery/metofficegovuk/images/weather/learn-about/weather/lenticular-cloud.jpg)\n",
    "taken from (https://www.metoffice.gov.uk/weather/learn-about/weather/types-of-weather/wind/lee-waves)\n",
    "\n",
    "# NWP data\n",
    "\n",
    "Lee waves can be identified in Numerical Weather Prediction (NWP) model output in a range of fields, such as vertical wind velocity just above topography. Below is an image of model output where lee waves are resolved, showing a characteristic stripey vertical velocity pattern. These patterns are easily picked up by eye, but not so easily detected automatically. To detect these patterns, typically spectral analysis is employed using idealised representations of waves.   \n",
    "\n",
    "![Example UKV data showing stripey lee waves in the verticle velocity output](https://rmets.onlinelibrary.wiley.com/cms/asset/10a1023d-3e98-4f26-9100-224ac84ea3d1/qj4592-fig-0001-m.jpg)\n",
    "\n",
    "(Figure 1 from [Coney et al 2023](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.4592))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3HgadAKV-lG"
   },
   "source": [
    "# Can Machine Learning help?\n",
    "\n",
    "The idea here is to use dimensionality reduction in order to identify and classify trapped lee waves without the need for imposing idealised wave models, so we can identify \"real-world\" wave characteristics. In this notebook, we will use NWP data together with a number of dimensionality reduction methods to apply a U-Net deep learning method. In this way, we will be able to identify regions of high lee wave activity and then diagnose real wave characteristics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy7xfsDzMMQ8"
   },
   "outputs": [],
   "source": [
    "# memory saving enable Pythons garbage collection\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcW8dJFCMMQ9"
   },
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "define two helper functions\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMmz4vpBMMQ9"
   },
   "outputs": [],
   "source": [
    "def open_xarray(fname):\n",
    "    # function to open data_arrays\n",
    "    # a function with this name is needed before loading the fastai learner in the next cell\n",
    "    x = xr.open_dataarray(fname)\n",
    "    array = x.values\n",
    "    return array\n",
    "\n",
    "def label_func(f):\n",
    "    # a function with this name is needed before loading the fastai learner in the next cell\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgToIyadrNUJ"
   },
   "source": [
    "# FastAI\n",
    "\n",
    "Load in a fastai learner object. First we download the data from hugging face in the below bash cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryM1HtMzmEyU"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://huggingface.co/LIFD-ENV-ML/dim_red_fast_ai_learner/resolve/main/learn2.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwbXgrHUMMQ9"
   },
   "outputs": [],
   "source": [
    "# load fastai learner object and get pytorch model with .model\n",
    "learner_inf = load_learner(\"learn2.pkl\")\n",
    "model = learner_inf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGsZa5X1KFyG"
   },
   "source": [
    "# Array set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgVHDlFyMMQ-"
   },
   "outputs": [],
   "source": [
    "# get arrays for simple data\n",
    "arrays = [np.array(list(range(0, 512))) for _ in range(512)]\n",
    "vals = np.stack(arrays, axis=1)\n",
    "vals = vals * np.pi / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHfPeGXYMMQ-"
   },
   "outputs": [],
   "source": [
    "# make dummy wave data with different wavelengths\n",
    "x0 = np.sin(vals / 4)\n",
    "x1 = np.sin(vals / 2)\n",
    "x2 = np.sin(vals)\n",
    "x3 = np.sin(vals.T)\n",
    "x4 = np.sin(vals * 2)\n",
    "x5 = np.sin(vals * 3)\n",
    "\n",
    "wl_waves = [x0, x1, x2, x3, x4, x5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wONNi5fIwHz"
   },
   "source": [
    "as we don't have 3 channels we have one wave repeated 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fmV1HjBMMQ_"
   },
   "outputs": [],
   "source": [
    "x_wavelength = torch.Tensor([[wave, wave, wave] for wave in wl_waves])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrxasWraI8YL"
   },
   "source": [
    "# Wavelength\n",
    "\n",
    "Run PCA wavelenghth function. We take the input tensor and run through the first part of our fast ai model which is the feature extraction.\n",
    "\n",
    "We then split the output into six samples and stack by features, and use PCA methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRHuML-hMMQ-"
   },
   "outputs": [],
   "source": [
    "def pca_wavelength(x_wavelength):\n",
    "    # function to take an input tensor, run it through the first part of the model\n",
    "    # and perform PCA on the intermediate model output\n",
    "\n",
    "    out = model[0](x_wavelength).detach().numpy()  # INTERMEDIATE MODEL OUTPUT\n",
    "    print(out.shape)  # should be 6 (batch size) * 512 features * 16 * 16\n",
    "    # out = input_tensor.numpy()\n",
    "    # THIS LINE IS IF WE WANTED TO PCA ON THE INPUT RATHER THAN THE INTERMEDIATE MODEL OUTPUT (AS FOR LINE ABOVE)\n",
    "    da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
    "    da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
    "    MethodClass = PCA\n",
    "    reduced_data = MethodClass(n_components=2).fit_transform(\n",
    "        da_stacked.values.T\n",
    "    )  # PERFORM PCA WITH TWO COMPONENTS\n",
    "\n",
    "    # CREATE DA OF PCA'd DATA\n",
    "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
    "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
    "    da = da_red.stack()\n",
    "\n",
    "    return da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E55fS8CAV6X1"
   },
   "source": [
    "Then we plot the waves, you can have a go playing around with different waves by editding x0 to x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHGqN-nVMMQ_"
   },
   "outputs": [],
   "source": [
    "# plot the input data with different wavelengths\n",
    "fig, ax = plt.subplots(1, len(wl_waves), figsize=(3 * len(wl_waves), 4))\n",
    "i = 0\n",
    "while i < len(wl_waves):\n",
    "    ax[i].imshow(wl_waves[i])\n",
    "    ax[i].set_title(i)\n",
    "    i += 1\n",
    "# plt.savefig(\"example_wvlgth_noise.jpg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwdyZzC_WNvR"
   },
   "source": [
    "running our fuction using the fastai learner objext and splitting into Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kha25DumMMQ_"
   },
   "outputs": [],
   "source": [
    "da = pca_wavelength(x_wavelength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sbJ3XgJWZrT"
   },
   "source": [
    "We can plot 2 principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzue2nr_MMQ_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the two PCA components for the wavelength data. Note that the data is approximately sorted L-R, with shorter wavelengths on the RHS and longer on the left\n",
    "# 2&3 are overlapping as they are the same wavelength but 90 degrees rotated from one another.\n",
    "fig, ax = plt.subplots()\n",
    "cmap = matplotlib.cm.get_cmap(\"viridis\")\n",
    "for sample in da.sample.values:\n",
    "    da_sample = da.sel(sample=sample)\n",
    "    ax.scatter(\n",
    "        da_sample.sel(pca_dim=0),\n",
    "        da_sample.sel(pca_dim=1),\n",
    "        label=sample,\n",
    "        c=cmap(sample / 5),\n",
    "        alpha=0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9iLa9ZlWvls"
   },
   "source": [
    "# Example rotating the waves\n",
    "\n",
    "We're now going to demonstrate an example rotatating our waves and using different manifold methods as well as PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fo5EuwVtMMRA"
   },
   "outputs": [],
   "source": [
    "# create data at various rotations\n",
    "x_rot0 = rotate(x2, -90, mode=\"wrap\", reshape=False)\n",
    "x_rot1 = rotate(x2, -60, mode=\"wrap\", reshape=False)\n",
    "x_rot2 = rotate(x2, -30, mode=\"wrap\", reshape=False)\n",
    "x_rot3 = rotate(x2, 0, mode=\"wrap\", reshape=False)\n",
    "x_rot4 = rotate(x2, 35, mode=\"wrap\", reshape=False)\n",
    "x_rot5 = rotate(x2, 60, mode=\"wrap\", reshape=False)\n",
    "x_rot6 = rotate(x2, 90, mode=\"wrap\", reshape=False)\n",
    "\n",
    "rot_waves = [\n",
    "    x_rot0,\n",
    "    x_rot1,\n",
    "    x_rot2,\n",
    "    x_rot3,\n",
    "    x_rot4,\n",
    "    x_rot5,\n",
    "    x_rot6,\n",
    "]  # , x_rot7, x_rot8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smhwXbXxMMRA"
   },
   "outputs": [],
   "source": [
    "x_rot = torch.Tensor([[wave, wave, wave] for wave in rot_waves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6zacXJ9MMRB"
   },
   "outputs": [],
   "source": [
    "# get intermediate model output from the rotated data\n",
    "out = model[0](x_rot).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZVLjgroMMRB"
   },
   "outputs": [],
   "source": [
    "# Plot three different types of model interpretation for the rotated data.\n",
    "da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
    "da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
    "methods = [SpectralEmbedding, Isomap, PCA]\n",
    "titles = [\"SpectralEmbedding\", \"Isomap\", \"PCA\"]\n",
    "\n",
    "i = 0\n",
    "fig, axes = plt.subplots(1, len(methods), figsize=(len(methods) * 6, 6))\n",
    "\n",
    "while i < len(methods):\n",
    "    ax = axes[i]\n",
    "    MethodClass = methods[i]\n",
    "    if MethodClass == \"Isomap\":\n",
    "        reduced_data = MethodClass(n_components=2, p=1).fit_transform(\n",
    "            da_stacked.values.T\n",
    "        )\n",
    "    else:\n",
    "        reduced_data = MethodClass(n_components=2).fit_transform(da_stacked.values.T)\n",
    "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
    "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
    "    da = da_red.stack()\n",
    "\n",
    "    for sample in da.sample.values:\n",
    "        da_sample = da.sel(sample=sample)\n",
    "        ax.scatter(\n",
    "            da_sample.sel(pca_dim=0), da_sample.sel(pca_dim=1), label=sample, alpha=0.5\n",
    "        )\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrvafoUtMMRB"
   },
   "outputs": [],
   "source": [
    "da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
    "da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
    "methods = [SpectralEmbedding, Isomap, PCA]\n",
    "titles = [\"SpectralEmbedding\", \"Isomap\", \"PCA\"]\n",
    "\n",
    "i = 0\n",
    "fig, axes = plt.subplots(1, len(methods), figsize=(len(methods) * 6, 6))\n",
    "\n",
    "while i < len(methods):\n",
    "    ax = axes[i]\n",
    "    MethodClass = methods[i]\n",
    "    if MethodClass == \"Isomap\":\n",
    "        reduced_data = MethodClass(n_components=1, p=1).fit_transform(\n",
    "            da_stacked.values.T\n",
    "        )\n",
    "    else:\n",
    "        reduced_data = MethodClass(n_components=2).fit_transform(da_stacked.values.T)\n",
    "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
    "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
    "    da = da_red.stack()\n",
    "    for sample in da.sample.values:\n",
    "        da_sample = da.sel(sample=sample)\n",
    "        ax.violinplot(\n",
    "            da_sample.sel(pca_dim=0),\n",
    "            #    alpha=0.5\n",
    "        )\n",
    "    #   ax.set_label(sample),\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "    # ax.legend()\n",
    "    i = i + 1\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYmReJ-nMMRB"
   },
   "source": [
    "# Adding noise\n",
    "\n",
    "What happens if we add noise to the synthetic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tr3RHGMSMMRC"
   },
   "outputs": [],
   "source": [
    "#\n",
    "def get_noise():\n",
    "    noise = np.random.random((512, 512))\n",
    "    noise = (noise - 0.5) * 4\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2_FFnLUMMRC"
   },
   "outputs": [],
   "source": [
    "x0 = np.sin(vals / 4) + get_noise()\n",
    "x1 = np.sin(vals / 2) + get_noise()\n",
    "x2 = np.sin(vals) + get_noise()\n",
    "x3 = np.sin(vals.T) + get_noise()\n",
    "x4 = np.sin(vals * 2) + get_noise()\n",
    "x5 = np.sin(vals * 3) + get_noise()\n",
    "\n",
    "wl_waves = [x0, x1, x2, x3, x4, x5]\n",
    "\n",
    "x_wavelength = torch.Tensor([[wave, wave, wave] for wave in wl_waves])\n",
    "\n",
    "da = pca_wavelength(x_wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNBigLndMMRC"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(wl_waves), figsize=(3 * len(wl_waves), 4))\n",
    "i = 0\n",
    "while i < len(wl_waves):\n",
    "    ax[i].imshow(wl_waves[i])\n",
    "    ax[i].set_title(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8uIykqhMMRC"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cmap = matplotlib.cm.get_cmap(\"viridis\")\n",
    "for sample in da.sample.values:\n",
    "    da_sample = da.sel(sample=sample)\n",
    "    ax.scatter(\n",
    "        da_sample.sel(pca_dim=0),\n",
    "        da_sample.sel(pca_dim=1),\n",
    "        label=sample,\n",
    "        c=cmap(sample / 5),\n",
    "        alpha=0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4BK7JSSMMRD"
   },
   "outputs": [],
   "source": [
    "x_rot0 = rotate(x2, -90, mode=\"wrap\", reshape=False)\n",
    "x_rot1 = rotate(x2, -60, mode=\"wrap\", reshape=False)\n",
    "x_rot2 = rotate(x2, -30, mode=\"wrap\", reshape=False)\n",
    "x_rot3 = rotate(x2, 0, mode=\"wrap\", reshape=False)\n",
    "x_rot4 = rotate(x2, 35, mode=\"wrap\", reshape=False)\n",
    "x_rot5 = rotate(x2, 60, mode=\"wrap\", reshape=False)\n",
    "x_rot6 = rotate(x2, 90, mode=\"wrap\", reshape=False)\n",
    "\n",
    "rot_waves = [\n",
    "    x_rot0,\n",
    "    x_rot1,\n",
    "    x_rot2,\n",
    "    x_rot3,\n",
    "    x_rot4,\n",
    "    x_rot5,\n",
    "    x_rot6,\n",
    "]  # , x_rot7, x_rot8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjK8HO_HMMRD"
   },
   "outputs": [],
   "source": [
    "x_rot = torch.Tensor([[wave, wave, wave] for wave in rot_waves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeuOIc2fMMRD"
   },
   "outputs": [],
   "source": [
    "out = model[0](x_rot).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wme_ADqsMMRD"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(rot_waves), figsize=(3 * len(rot_waves), 4))\n",
    "i = 0\n",
    "while i < len(rot_waves):\n",
    "    ax[i].imshow(rot_waves[i])\n",
    "    ax[i].set_title(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aw_P893uMMRD"
   },
   "outputs": [],
   "source": [
    "da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
    "da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
    "methods = [SpectralEmbedding, Isomap, PCA]\n",
    "titles = [\"SpectralEmbedding\", \"Isomap\", \"PCA\"]\n",
    "\n",
    "i = 0\n",
    "fig, axes = plt.subplots(1, len(methods), figsize=(len(methods) * 6, 6))\n",
    "\n",
    "while i < len(methods):\n",
    "    ax = axes[i]\n",
    "    MethodClass = methods[i]\n",
    "    if MethodClass == \"Isomap\":\n",
    "        reduced_data = MethodClass(n_components=1, p=1).fit_transform(\n",
    "            da_stacked.values.T\n",
    "        )\n",
    "    else:\n",
    "        reduced_data = MethodClass(n_components=2).fit_transform(da_stacked.values.T)\n",
    "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
    "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
    "    da = da_red.stack()\n",
    "\n",
    "    for sample in da.sample.values:\n",
    "        da_sample = da.sel(sample=sample)\n",
    "        ax.scatter(\n",
    "            da_sample.sel(pca_dim=0), da_sample.sel(pca_dim=1), label=sample, alpha=0.5\n",
    "        )\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
