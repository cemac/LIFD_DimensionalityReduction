{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemac/LIFD_DimensionalityReduction/blob/main/LIFD_dimensionality_reduction_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame #Display YouTube videos\n"
      ],
      "metadata": {
        "id": "mDBjgBPAaCjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T12:37:35.131452Z",
          "iopub.status.busy": "2022-06-15T12:37:35.131014Z",
          "iopub.status.idle": "2022-06-15T12:37:55.67664Z",
          "shell.execute_reply": "2022-06-15T12:37:55.675474Z",
          "shell.execute_reply.started": "2022-06-15T12:37:35.131414Z"
        },
        "id": "KceBOmdOMMQ3"
      },
      "source": [
        "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
        "    <h1> Tutorial 7 </h1>\n",
        "    <h2> Dimensionality Reduction </h2>\n",
        "</div>      \n",
        "\n",
        "\n",
        "# Overview\n",
        "\n",
        "This Jupyter notebook is based off Johnathan Coney's work on Identifying and characterising trapped lee waves using dimensionality reduction. This work is outline in [Coney et al, 2023](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.4592). This notebook will go through the basics of [Principal Component Analysis](https://www.billconnelly.net/?p=697) and Dimensionality Reduction methods using some toy code from a kaggle tutorial using the MNIST dataset and then apply those methods to an Earth Science application based on Johnathan Coney's Work.\n",
        "\n",
        "\n",
        "## The very basics\n",
        "\n",
        "If you know nothing about neural networks there is a [toy neural network python code example](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/tree/main/ToyNeuralNetwork) included in the [LIFD ENV ML Notebooks Repository]( https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS). Creating a 2 layer neural network to illustrate the fundamentals of how Neural Networks work and the equivlent code using the python machine learning library [keras](https://keras.io/).\n",
        "\n",
        "\n",
        "## Recommended reading\n",
        "\n",
        "\n",
        "* [All you need to know on Neural networks](https://suryansh.xyz/articles/nn_aynk)\n",
        "* [Introduction to Neural Networks](https://victorzhou.com/blog/intro-to-neural-networks/)\n",
        "* [Coney, J., Denby, L., Ross, A.N., Wang, H., Vosper, S., van Niekerk, A., et al. (2023) Identifying and characterising trapped lee waves using deep learning techniques. Quarterly Journal of the Royal Meteorological Society, 1–19.](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.4592)\n",
        "* [Kaggle PCA tutorial](https://www.kaggle.com/code/vipulgandhi/pca-beginner-s-guide-to-dimensionality-reduction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJWHfz3xMMQ5"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
        "    \n",
        "<h1> Machine Learning Theory </h1>\n",
        "\n",
        "# Dimensionality Reduction\n",
        "\n",
        "## The problem\n",
        "\n",
        "Data with more features becomes more complex and the greater chance we have of simply overfitting our model. So dimension reduction is a possible solution to this by reducing the number of features to make a simpler model. There are a number of methods to do this an still retain a lot of imformation.\n",
        "\n",
        "## The benefits of dimensionality reductions:\n",
        "\n",
        "1. Less misleading data to improve accuracy\n",
        "2. Less dimensions will be faster to train model\n",
        "3. Less dimensions gives a larger number of possible algorithums to work with\n",
        "4. Smaller amount of data so takes up less storage\n",
        "5. Removes noise\n",
        "6. Can help with plotting as its easy to visualise 2D space\n",
        "\n",
        "## The Main methods of Dimensionalit Reduction\n",
        "\n",
        "This is done by feature extraction or feature engineering. Feature extraction can vary from simple projection methods like Pricipal Component Analysis or via more complex manifold methods like t-SNE\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis\n",
        "\n",
        "PCA works by linearly mapping data to a lower-dimensional space in a way that maximises variance (to preserve information). The new features are orthogonal i.e. uncorrelated and are ranked in order of their explained variance. The first pricipal compontent explains the most variance in the data, the second the second most and so on.\n",
        "\n",
        "The first part of this tutorial will go through the steps of PCA. If you find you need a refesher on your vector calculus you might find these pages on [determinants](https://www.mathsisfun.com/algebra/matrix-determinant.html) and [Eigen Vectors](https://www.mathsisfun.com/algebra/eigenvalue.html) helpful!\n",
        "\n",
        "The following two videos from statquest cover the basics of PCA and its relation to dimensionality reduction"
      ],
      "metadata": {
        "id": "uodHXZMLaG79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IFrame(\"https://www.youtube.com/embed/FgakZw6K1QQ?si=WSQfwg7Ig2yftWvT\",\"560\", \"315\" )"
      ],
      "metadata": {
        "id": "TDuEELUTZmyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IFrame(\"https://www.youtube.com/embed/HMOI_lkzW08?si=gMNZlGBn36qZ9lZC\",\"560\", \"315\" )\n"
      ],
      "metadata": {
        "id": "QXSK6KceaGbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimension Manifold Methods\n",
        "\n",
        "\n",
        "Dimension reduction isn't confine to just PCA methods there are also manifold methods. Some times the data might be too complex for projection methods such as linear PCA. Manifold techniques measure how each training instance linearly relates to its nearest neighbors, then it looks for a low-dimensional representation of the training set where these local relationships are best preserved. Here we will look at at MDS (multidemsional scaling) and Isomap (Isometric Mapping) techniques. Another commonly used technique is Uniform Manifold Approximation and Projection (UMAP) and there is a great explaination of it in [this article](https://shubh-tripathi.medium.com/decrypted-dimensionality-reduction-4064bfecb87f). (Note UMAP often superceeds ISOMAP technique.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kTKPfo79bB-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## U-Net and Segmentation\n",
        "\n",
        "The [U-Net](https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/) model architecture is a convolutional neural network that consists of an encoder and a decoder. The encoder extracts features from 2D input images by coarse-graining the input data with increasing depth in the network and compositing learned features. The decoder uses the patterns extracted by the encoder and upsamples the data, so that a prediction can be made for each pixel. In addition, the upsampled data are combined with data from the encoder at the same level (skip-connections). These skip-connections allow the U-Net to retain high spatial fidelity by combining the up-scaled values in the decoder with more spatially dense values from the encoder. As shown in the diagram below.\n",
        "\n",
        "Finally, the head is where the remaining pixelwise learnt spatial features are further manipulated through pixelwise transforms to produce predictions per pixel.\n",
        "\n",
        "![Schematic of U Net](https://rmets.onlinelibrary.wiley.com/cms/asset/20265527-45ca-4fac-8de3-5b32f9e73c63/qj4592-fig-0004-m.jpg)\n",
        "\n",
        "In this tutorial we'll be using pretrained [fastai](https://www.fast.ai/) learner object: [Dynamic U-Net](https://www.mdpi.com/2078-2489/11/2/108) this model is designed to extract patterns from data. So building the U Net will not be covered in this notebook.\n",
        "\n",
        "</div>    "
      ],
      "metadata": {
        "id": "C7PjzQ01RM29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IFrame(\"https://www.youtube.com/embed/NhdzGfB1q74?si=p8ti5ydxXvqJuABi\",\"560\", \"315\" )"
      ],
      "metadata": {
        "id": "OfUQlcc_b6Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3T1ImzFMMQ5"
      },
      "source": [
        "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
        "\n",
        "# Python\n",
        "    \n",
        "    \n",
        "## [PyTorch](https://pytorch.org/) & [sci-kit learn](https://scikit-learn.org/stable/index.html)\n",
        "\n",
        "The two base machine learning libraries uese in this tutorial are Pytorch and sci-kit learn. sci-kit learn is a light weight machine learning library that can be used for PCA and manifold dimensionality reduction methods and Pytorch is required for our deeplearning fastai segmentation model refered to in our more complex Earth Science example.\n",
        "\n",
        "\n",
        "## [FastAI](https://www.fast.ai/)\n",
        "\n",
        "A library of machine learning that allows you create deep learning models in just a few lines of code. The library come pre installed on google colab, or easily installed via conda or pip. The library uses the underlying commonality in deep learning tasks broken down in vision, text, tabular or collaborative filtering applications. In all likelihood there is already a model configured and trained for a very similar application that you're looking to do.   \n",
        "\n",
        "Read more about Fast AI [here](https://docs.fast.ai/)\n",
        "\n",
        "For applications used in this tutorial the [vision fastai tutorial](https://docs.fast.ai/tutorial.vision.html) covers all the methods used here.  \n",
        "\n",
        "## Further Reading\n",
        "\n",
        "If you want to run this notebook locally or on a remote service\n",
        "\n",
        "\n",
        "* [Running Jupyter Notebooks](https://jupyter.readthedocs.io/en/latest/running.html#running)\n",
        "* [installing the required python environments](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/blob/main/howtorun.md)\n",
        "* [running the jupyter notebooks locally](https://github.com/cemac/LIFD_ENV_ML_NOTEBOOKS/blob/main/jupyter_notebooks.md)\n",
        "    \n",
        "</div>\n",
        "    \n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR2lCmA4MMQ6"
      },
      "source": [
        "<div style=\"background-color: #ffffcc; padding: 10px;\">\n",
        "    \n",
        "<h1> Requirements </h1>\n",
        "\n",
        "These notebooks should run with the following requirements satisfied\n",
        "\n",
        "<h2> Python Packages: </h2>\n",
        "\n",
        "* Python 3.8\n",
        "* fastai\n",
        "* pytorch\n",
        "* sklearn\n",
        "* albumentations\n",
        "* numpy\n",
        "* pandas\n",
        "* xarray\n",
        "* matplotlib  \n",
        "\n",
        "<h2> Data Requirements</h2>\n",
        "    \n",
        "This notebook referes to some small external datasets and learner object with are downloaded via bash scripts within the notebooks\n",
        "\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQZHsRyrMMQ6"
      },
      "source": [
        "**Contents:**\n",
        "\n",
        "1. [Overview and background information](#)\n",
        "2. [Introduction to PCA, and manifold methods](#)\n",
        "3. [Background information to Earth Science Application](#)\n",
        "4. [Example locating and classification of trapped lee waves](#)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExBFkWj9MMQ6"
      },
      "source": [
        "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
        "\n",
        "# Import modules\n",
        "\n",
        "These are all the modules needed during this tutorial\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T12:37:55.68393Z",
          "iopub.status.busy": "2022-06-15T12:37:55.681792Z",
          "iopub.status.idle": "2022-06-15T12:37:55.882543Z",
          "shell.execute_reply": "2022-06-15T12:37:55.88186Z",
          "shell.execute_reply.started": "2022-06-15T12:37:55.683887Z"
        },
        "id": "zJ7oZ_AJMMQ7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# For readability: disable warnings not reccomended outside of tutorial setting!\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T13:05:55.876301Z",
          "iopub.status.busy": "2022-06-15T13:05:55.875847Z",
          "iopub.status.idle": "2022-06-15T13:05:55.898805Z",
          "shell.execute_reply": "2022-06-15T13:05:55.897995Z",
          "shell.execute_reply.started": "2022-06-15T13:05:55.876263Z"
        },
        "id": "V5fhtQBQMMQ7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import modules\n",
        "# general file system utilites\n",
        "import os\n",
        "import gc\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "# Plotting utilies\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Machine Learning Libraries Fastai, PyTorch and Sklearn\n",
        "import fastai\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from fastai.vision.all import *\n",
        "from fastai.data.transforms import get_files, RandomSplitter\n",
        "from fastai.learner import Learner\n",
        "import albumentations as A\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import Isomap, SpectralEmbedding, TSNE\n",
        "from scipy.ndimage import rotate\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from matplotlib.ticker import NullFormatter\n",
        "from sklearn import manifold\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# path finding for windows systems\n",
        "if os.name=='nt':\n",
        "    import pathlib\n",
        "    temp = pathlib.PosixPath\n",
        "    pathlib.PosixPath = pathlib.WindowsPath"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). This dataset is an example dataset that is often used to practice data science techniques such as PCA. It's lightweight having only 4 features and 150 entries.\n",
        "\n",
        "We'll download the data and take a quick look at the data below."
      ],
      "metadata": {
        "id": "EAmkmciOCtAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
        "#rename columns\n",
        "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "\n",
        "#drop null\n",
        "iris.dropna()"
      ],
      "metadata": {
        "id": "0p94bLPaChbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can quickly make a scatter plot of petal length and width and colour by species. Setosa in red, Virginica in green and Versicolour in blue. We can clearly see there are 3 distinct clusers in the dataset so this should be a good dataset to demonstrate Prinicipal Component Analysis."
      ],
      "metadata": {
        "id": "tOaL23wtb56N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colour_list = iris['species'].values\n",
        "colour_list = [c.replace('Iris-setosa', 'r') for c in colour_list]\n",
        "colour_list = [c.replace('Iris-virginica', 'g') for c in colour_list]\n",
        "colour_list = [c.replace('Iris-versicolor', 'b') for c in colour_list]"
      ],
      "metadata": {
        "id": "l2oid7n3YJly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(iris['petal_length'].values, iris['petal_width'].values, c=colour_list)\n",
        "plt.title('clusters by petal length + width')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d6exs_mdXB1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we replace petal width and length with sepal length and width, we can still see the species clusters."
      ],
      "metadata": {
        "id": "dOUkuSyBdc07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(iris['sepal_length'].values, iris['sepal_width'].values, c=colour_list)\n",
        "plt.title('clusters by sepal length + width')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PSORIRVedYIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This where PCA comes in handy. By eye we can see that both sepal and petal information independently give species information. This will allow us to use all the information and more robustly separate our clusters."
      ],
      "metadata": {
        "id": "zRUEiQpaeIBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start by standardizing our dataset, otherwise larger ranges will dominate over smaller range variables, we'll use scikit learns standardscaler function."
      ],
      "metadata": {
        "id": "JlQLZhI9fxuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris[['sepal_length','sepal_width','petal_length','petal_width']]\n",
        "y=iris.species"
      ],
      "metadata": {
        "id": "IUatw3JjCmIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = StandardScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "XUf59p6mGBkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eigendecomposition\n",
        "\n",
        "The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the “core” of a PCA: The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude. In other words, the eigenvalues explain the variance of the data along the new feature axes.\n",
        "Covariance Matrix\n",
        "\n",
        "The classic approach to PCA is to perform the eigendecomposition on the covariance matrix , which is a matrix where each element represents the covariance between two features. The covariance between two features is calculated as follows:\n",
        "\n",
        "\n",
        "Cov(𝑋, 𝑌 ) = \\frac{\\sum(x_i - \\bar{x}) (y_i - \\bar{y})}{N-1}\n",
        "\n"
      ],
      "metadata": {
        "id": "TvU_-KDBgX2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean = np.mean(X, axis=0)\n",
        "# cov_mat = np.cov(X)\n",
        "cov_mat = (X - X_mean).T.dot((X - X_mean)) / (X.shape[0]-1)\n",
        "print('Covariance matrix \\n%s' %cov_mat)"
      ],
      "metadata": {
        "id": "e9Eaw0KDGDRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
        "\n",
        "print('Eigenvectors \\n%s' %eig_vecs)\n",
        "print('\\nEigenvalues \\n%s' %eig_vals)"
      ],
      "metadata": {
        "id": "6ZJ08BpOGDZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Singular Value Decomposition\n",
        "\n",
        "While the eigendecomposition of the covariance or correlation matrix may be more intuitiuve, most PCA implementations perform a Singular Value Decomposition (SVD) to improve the computational efficiency. So, let us perform an SVD to confirm that the result are indeed the same:\n"
      ],
      "metadata": {
        "id": "IIe9-M5EgzW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u,s,v = np.linalg.svd(X.T)\n",
        "u"
      ],
      "metadata": {
        "id": "pCgbw9PbGDgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Principal Components\n",
        "\n",
        "Sorting Eigenpairs\n",
        "\n",
        "The goal of PCA is to reduce the dimensionality of the original feature space by projecting it onto a smaller subspace, where the eigenvectors will form the axes. However, the eigenvectors only define the directions of the new axis, since they all have the same unit length 1.\n",
        "\n",
        "In order to decide which eigenvector(s) can be dropped without losing too much information, we need to inspect the corresponding eigenvalues: The eigenvectors with the lowest eigenvalues bear the least information about the distribution of the data; those are the ones can be dropped.\n",
        "\n",
        "The common approach is to rank the eigenvalues from highest to lowest.\n"
      ],
      "metadata": {
        "id": "rfyRadGghCLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a list of (eigenvalue, eigenvector) tuples\n",
        "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
        "\n",
        "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
        "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
        "print('Eigenvalues in descending order:')\n",
        "for i in eig_pairs:\n",
        "    print(i[0])"
      ],
      "metadata": {
        "id": "J5rEbBIhGDkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Explained Variance\n",
        "\n",
        "After sorting the eigenpairs, the next question is “how many principal components are we going to choose for our new feature subspace?” A useful measure is the so-called “explained variance,” which can be calculated from the eigenvalues. The explained variance tells us how much information (variance) can be attributed to each of the principal components.\n"
      ],
      "metadata": {
        "id": "c05Nf4aKhHd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tot = sum(eig_vals)\n",
        "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "cum_var_exp\n"
      ],
      "metadata": {
        "id": "hK-ee6ldGNWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Projection Matrix\n",
        "\n",
        "The projection matrix is used to transform the Input data(X) onto the new feature subspace. Projection Matrix is a matrix of concatenated top k eigenvectors.\n",
        "\n",
        "Here, we are reducing the 4-dimensional feature space to a 2-dimensional feature subspace, by choosing the “top 2” eigenvectors with the highest eigenvalues to construct our 2-dimensional eigenvector matrix .\n"
      ],
      "metadata": {
        "id": "wrZESBMvhMMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1),\n",
        "                      eig_pairs[1][1].reshape(4,1)))\n",
        "\n",
        "print('Matrix W:\\n', matrix_w)\n",
        "\n"
      ],
      "metadata": {
        "id": "CRMP_2ZfGNqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Projection Onto the New Feature Space"
      ],
      "metadata": {
        "id": "6pzBqCeghPGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Y = X.dot(matrix_w)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8s3GPqTGNve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with plt.style.context('seaborn-whitegrid'):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), ('blue', 'red', 'green')):\n",
        "        plt.scatter(Y[y==lab, 0], Y[y==lab, 1], label=lab, c=col)\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.legend(loc='lower center')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-0ZznZAvGU1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using SciKit Learns inbuilt functions!"
      ],
      "metadata": {
        "id": "DpP0CuPyhT6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_pca = PCA(n_components=2)\n",
        "Y_sklearn = sklearn_pca.fit_transform(X)\n",
        "\n",
        "sklearn_pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "n-N2J05GGU5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with plt.style.context('seaborn-whitegrid'):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n",
        "                        ('blue', 'red', 'green')):\n",
        "        plt.scatter(Y_sklearn[y==lab, 0],\n",
        "                    Y_sklearn[y==lab, 1],\n",
        "                    label=lab,\n",
        "                    c=col)\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.legend(loc='lower center')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "gACFKq0TGU80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manifold Learning\n",
        "\n",
        "We'll use some in built functions to demonstrate various variations of this with some Manifold Learning tecnhiques"
      ],
      "metadata": {
        "id": "d0Kz_3bmhjRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "color = LabelEncoder().fit_transform(y)\n",
        "\n",
        "Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(15, 8))\n",
        "n_components=3\n",
        "n_neighbors=5\n",
        "\n",
        "#----PCA---------- sklearn implementation\n",
        "\n",
        "pca = PCA(n_components=n_components)\n",
        "Y = pca.fit_transform(X)\n",
        "\n",
        "ax = fig.add_subplot(131, projection='3d')\n",
        "ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)\n",
        "ax.view_init(4, -72)\n",
        "plt.title(\"PCA\")\n",
        "\n",
        "ax.axis('tight')\n",
        "#--------------------\n",
        "#----MDS---------- sklearn implementation (Stress minimization-majorization algorithm SMACOF)\n",
        "\n",
        "mds = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
        "Y = mds.fit_transform(X)\n",
        "\n",
        "ax = fig.add_subplot(132, projection='3d')\n",
        "ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)\n",
        "ax.view_init(4, -72)\n",
        "plt.title(\"MDS\")\n",
        "\n",
        "ax.axis('tight')\n",
        "#---------------\n",
        "#----Isomap---------- sklearn implementation (with kernel PCA)\n",
        "\n",
        "Y = manifold.Isomap(n_neighbors=n_neighbors,n_components=n_components).fit_transform(X)\n",
        "\n",
        "ax = fig.add_subplot(133, projection='3d')\n",
        "ax.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=color, cmap=plt.cm.Spectral)\n",
        "ax.view_init(4, -72)\n",
        "plt.title(\"Isomap\")\n",
        "\n",
        "ax.axis('tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3wpt0-TrGqJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the second part of the tutorial we'll use these techniques to go over an applied example:\n",
        "\n"
      ],
      "metadata": {
        "id": "Pfo5F8rAh1yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "# Background for application to Earth Sciences"
      ],
      "metadata": {
        "id": "M78dr9ucclFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To give you an example of a real research application in Earth Sciences, we'll follow through the steps of how dimensionality reduction was used to identify and characterise\n",
        "\n",
        "# Gravity Waves\n",
        "\n",
        "A gravity wave is a vertical wave for example ripples, in the atmosphere gravity waves can be formed when air is forced upwards by topography (e.g. wind blowing over a mountain), this creates turbulance in the air that can be felt throughout the coloumn of air above a montain. This would be of interest to improve our understanding and forecasting capability for aviation for example. If you'd like to learn more NOAA have a useful information page all about gravity waves in the atmosphere [here](https://www.weather.gov/source/zhu/ZHU_Training_Page/Miscellaneous/gravity_wave/gravity_wave.html)\n",
        "\n",
        "![diagram of gravity waves](https://www.weather.gov/source/zhu/ZHU_Training_Page/Miscellaneous/gravity_wave/radarscope2.png)\n",
        "(taken from https://www.weather.gov/source/zhu/ZHU_Training_Page/Miscellaneous/gravity_wave/gravity_wave.html)\n",
        "\n",
        "Lee waves can be observed by eye as you get clouds forming on the crest of the wave e.g. when you look up and see stripes of clouds or lenticular clouds like the image seen below where a mountain has forced a wave in the air to form. These can be spotted in photos and satalite images. For more information the metoffice have a basic overview [here](https://www.metoffice.gov.uk/weather/learn-about/weather/types-of-weather/wind/lee-waves)\n",
        "\n",
        "![Lenticular cloud over mountains image](https://www.metoffice.gov.uk/binaries/content/gallery/metofficegovuk/images/weather/learn-about/weather/lenticular-cloud.jpg)\n",
        "taken from (https://www.metoffice.gov.uk/weather/learn-about/weather/types-of-weather/wind/lee-waves)\n",
        "\n",
        "# NWP data\n",
        "\n",
        "Leewaves can be identified in Numerical Weather Prediction model output in a range of fields such as vertical wind velocity just above topography, below is an image of model output where leewaves are resolved showing a characteritic stripey vertical velocity pattern. These patterns are easily picked up by eye, but not so easily automacticaly dectected. To detect these patterns typically spectral analysis is imployed using idealised representations of waves.   \n",
        "\n",
        "![Example UKV data showing stripey lee waves in the verticle velocity output](https://rmets.onlinelibrary.wiley.com/cms/asset/467e0f37-4cac-4a29-8556-1eff69d90a3d/qj4592-fig-0001-m.jpg)\n",
        "\n",
        "(Figure 1 from [Coney et al 2023](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.4592))"
      ],
      "metadata": {
        "id": "sKCow81WOJhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Can can ML help?\n",
        "\n",
        "The idea here is to use dimensionality reduction in oder to identify and classify trapped leewaves without the need for imposing idealised wave models so we can identify \"real-world\" wave characteristics. In this notebook we will use NWP data and a number of dimensionality reduction methos to apply a U-Net deep learning method to identify regions of high lee wave activity and then diagnose real wave characteristics.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3HgadAKV-lG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy7xfsDzMMQ8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# memory saving enable pythons garbage collection\n",
        "gc.enable()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcW8dJFCMMQ9"
      },
      "source": [
        "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
        "define two helper functions\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T12:38:52.133712Z",
          "iopub.status.busy": "2022-06-15T12:38:52.132922Z",
          "iopub.status.idle": "2022-06-15T12:38:52.149513Z",
          "shell.execute_reply": "2022-06-15T12:38:52.148603Z",
          "shell.execute_reply.started": "2022-06-15T12:38:52.133669Z"
        },
        "id": "fMmz4vpBMMQ9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def open_xarray(fname):\n",
        "    # function to open data_arrays\n",
        "    # a function with this name is needed before loading the fastai learner in the next cell\n",
        "    x = xr.open_dataarray(fname)\n",
        "    array = x.values\n",
        "    return array\n",
        "\n",
        "\n",
        "def label_func(f):\n",
        "    # a function with this name is needed before loading the fastai learner in the next cell\n",
        "    return f"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FastAI\n",
        "\n",
        "Load in a fastai learner object. First we download the data from hugging face in the below bash cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "KgToIyadrNUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%bash\n",
        "\n",
        "wget https://huggingface.co/LIFD-ENV-ML/dim_red_fast_ai_learner/resolve/main/learn2.pkl"
      ],
      "metadata": {
        "id": "ryM1HtMzmEyU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T12:38:52.564021Z",
          "iopub.status.busy": "2022-06-15T12:38:52.563538Z",
          "iopub.status.idle": "2022-06-15T12:38:55.002119Z",
          "shell.execute_reply": "2022-06-15T12:38:54.988886Z",
          "shell.execute_reply.started": "2022-06-15T12:38:52.563981Z"
        },
        "id": "DwbXgrHUMMQ9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load fastai learner object and get pytorch model with .model\n",
        "learner_inf = load_learner(\"learn2.pkl\")\n",
        "model = learner_inf.model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Array set up"
      ],
      "metadata": {
        "id": "NGsZa5X1KFyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T12:38:55.921904Z",
          "iopub.status.busy": "2022-06-15T12:38:55.921405Z",
          "iopub.status.idle": "2022-06-15T12:38:56.000521Z",
          "shell.execute_reply": "2022-06-15T12:38:55.999818Z",
          "shell.execute_reply.started": "2022-06-15T12:38:55.921862Z"
        },
        "id": "LgVHDlFyMMQ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# get arrays for simple data\n",
        "arrays = [np.array(list(range(0, 512))) for _ in range(512)]\n",
        "vals = np.stack(arrays, axis=1)\n",
        "vals = vals * np.pi / 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T12:38:56.503144Z",
          "iopub.status.busy": "2022-06-15T12:38:56.502282Z",
          "iopub.status.idle": "2022-06-15T12:38:56.558525Z",
          "shell.execute_reply": "2022-06-15T12:38:56.557769Z",
          "shell.execute_reply.started": "2022-06-15T12:38:56.503102Z"
        },
        "id": "zHfPeGXYMMQ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# make dummy wave data with different wavelengths\n",
        "x0 = np.sin(vals / 4)\n",
        "x1 = np.sin(vals / 2)\n",
        "x2 = np.sin(vals)\n",
        "x3 = np.sin(vals.T)\n",
        "x4 = np.sin(vals * 2)\n",
        "x5 = np.sin(vals * 3)\n",
        "\n",
        "wl_waves = [x0, x1, x2, x3, x4, x5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we don't have 3 channels we have one wave repeated 3 times"
      ],
      "metadata": {
        "id": "5wONNi5fIwHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T11:00:01.358317Z",
          "iopub.status.busy": "2022-06-15T11:00:01.357702Z",
          "iopub.status.idle": "2022-06-15T11:00:01.815146Z",
          "shell.execute_reply": "2022-06-15T11:00:01.814282Z",
          "shell.execute_reply.started": "2022-06-15T11:00:01.358275Z"
        },
        "id": "7fmV1HjBMMQ_"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_wavelength = torch.Tensor([[wave, wave, wave] for wave in wl_waves])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wavelength\n",
        "\n",
        "Run PCA wavelenghth function. We take the input tensor and run through the first part of our fast ai model which is the feature extraction.\n",
        "\n",
        "We then split the output into six samples and stack by features, and use PCA methods"
      ],
      "metadata": {
        "id": "hrxasWraI8YL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRHuML-hMMQ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pca_wavelength(x_wavelength):\n",
        "    # function to take an input tensor, run it through the first part of the model\n",
        "    # and perform PCA on the intermediate model output\n",
        "\n",
        "    out = model[0](x_wavelength).detach().numpy()  # INTERMEDIATE MODEL OUTPUT\n",
        "    print(out.shape)  # should be 6 (batch size) * 512 features * 16 * 16\n",
        "    # out = input_tensor.numpy()\n",
        "    # THIS LINE IS IF WE WANTED TO PCA ON THE INPUT RATHER THAN THE INTERMEDIATE MODEL OUTPUT (AS FOR LINE ABOVE)\n",
        "    da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
        "    da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
        "    MethodClass = PCA\n",
        "    reduced_data = MethodClass(n_components=2).fit_transform(\n",
        "        da_stacked.values.T\n",
        "    )  # PERFORM PCA WITH TWO COMPONENTS\n",
        "\n",
        "    # CREATE DA OF PCA'd DATA\n",
        "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
        "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
        "    da = da_red.stack()\n",
        "\n",
        "    return da"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we plot the waves, you can have a go playing around with different waves by editding x0 to x5"
      ],
      "metadata": {
        "id": "E55fS8CAV6X1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHGqN-nVMMQ_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot the input data with different wavelengths\n",
        "fig, ax = plt.subplots(1, len(wl_waves), figsize=(3 * len(wl_waves), 4))\n",
        "i = 0\n",
        "while i < len(wl_waves):\n",
        "    ax[i].imshow(wl_waves[i])\n",
        "    ax[i].set_title(i)\n",
        "    i += 1\n",
        "# plt.savefig(\"example_wvlgth_noise.jpg\", bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "running our fuction using the fastai learner objext and splitting into Principal components"
      ],
      "metadata": {
        "id": "IwdyZzC_WNvR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T10:54:37.273024Z",
          "iopub.status.busy": "2022-06-15T10:54:37.272173Z",
          "iopub.status.idle": "2022-06-15T10:54:37.281231Z",
          "shell.execute_reply": "2022-06-15T10:54:37.280341Z",
          "shell.execute_reply.started": "2022-06-15T10:54:37.272976Z"
        },
        "id": "Kha25DumMMQ_"
      },
      "outputs": [],
      "source": [
        "\n",
        "da = pca_wavelength(x_wavelength)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can plot 2 principal component"
      ],
      "metadata": {
        "id": "_sbJ3XgJWZrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T10:54:37.434341Z",
          "iopub.status.busy": "2022-06-15T10:54:37.433684Z",
          "iopub.status.idle": "2022-06-15T10:54:37.721763Z",
          "shell.execute_reply": "2022-06-15T10:54:37.720946Z",
          "shell.execute_reply.started": "2022-06-15T10:54:37.434303Z"
        },
        "scrolled": true,
        "id": "Pzue2nr_MMQ_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot the two PCA components for the wavelength data. Note that the data is approximately sorted L-R, with shorter wavelengths on the RHS and longer on the left\n",
        "# 2&3 are overlapping as they are the same wavelength but 90 degrees rotated from one another.\n",
        "fig, ax = plt.subplots()\n",
        "cmap = matplotlib.cm.get_cmap(\"viridis\")\n",
        "for sample in da.sample.values:\n",
        "    da_sample = da.sel(sample=sample)\n",
        "    ax.scatter(\n",
        "        da_sample.sel(pca_dim=0),\n",
        "        da_sample.sel(pca_dim=1),\n",
        "        label=sample,\n",
        "        c=cmap(sample / 5),\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example rotating the waves\n",
        "\n",
        "We're now going to demonstrate an example rotatating our waves and using different manifold methods as well as PCA."
      ],
      "metadata": {
        "id": "D9iLa9ZlWvls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo5EuwVtMMRA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create data at various rotations\n",
        "x_rot0 = rotate(x2, -90, mode=\"wrap\", reshape=False)\n",
        "x_rot1 = rotate(x2, -60, mode=\"wrap\", reshape=False)\n",
        "x_rot2 = rotate(x2, -30, mode=\"wrap\", reshape=False)\n",
        "x_rot3 = rotate(x2, 0, mode=\"wrap\", reshape=False)\n",
        "x_rot4 = rotate(x2, 35, mode=\"wrap\", reshape=False)\n",
        "x_rot5 = rotate(x2, 60, mode=\"wrap\", reshape=False)\n",
        "x_rot6 = rotate(x2, 90, mode=\"wrap\", reshape=False)\n",
        "\n",
        "rot_waves = [\n",
        "    x_rot0,\n",
        "    x_rot1,\n",
        "    x_rot2,\n",
        "    x_rot3,\n",
        "    x_rot4,\n",
        "    x_rot5,\n",
        "    x_rot6,\n",
        "]  # , x_rot7, x_rot8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T13:19:31.569675Z",
          "iopub.status.busy": "2022-06-15T13:19:31.569232Z",
          "iopub.status.idle": "2022-06-15T13:19:32.335709Z",
          "shell.execute_reply": "2022-06-15T13:19:32.334942Z",
          "shell.execute_reply.started": "2022-06-15T13:19:31.569634Z"
        },
        "id": "smhwXbXxMMRA"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_rot = torch.Tensor([[wave, wave, wave] for wave in rot_waves])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T13:19:32.342125Z",
          "iopub.status.busy": "2022-06-15T13:19:32.339931Z",
          "iopub.status.idle": "2022-06-15T13:19:35.314123Z",
          "shell.execute_reply": "2022-06-15T13:19:35.313308Z",
          "shell.execute_reply.started": "2022-06-15T13:19:32.342082Z"
        },
        "id": "w6zacXJ9MMRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# get intermediate model output from the rotated data\n",
        "out = model[0](x_rot).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T13:20:07.438695Z",
          "iopub.status.busy": "2022-06-15T13:20:07.438253Z",
          "iopub.status.idle": "2022-06-15T13:20:08.053849Z",
          "shell.execute_reply": "2022-06-15T13:20:08.052808Z",
          "shell.execute_reply.started": "2022-06-15T13:20:07.438657Z"
        },
        "id": "BZVLjgroMMRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot three different types of model interpretation for the rotated data.\n",
        "da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
        "da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
        "methods = [SpectralEmbedding, Isomap, PCA]\n",
        "titles = [\"SpectralEmbedding\", \"Isomap\", \"PCA\"]\n",
        "\n",
        "i = 0\n",
        "fig, axes = plt.subplots(1, len(methods), figsize=(len(methods) * 6, 6))\n",
        "\n",
        "while i < len(methods):\n",
        "    ax = axes[i]\n",
        "    MethodClass = methods[i]\n",
        "    if MethodClass == \"Isomap\":\n",
        "        reduced_data = MethodClass(n_components=2, p=1).fit_transform(\n",
        "            da_stacked.values.T\n",
        "        )\n",
        "    else:\n",
        "        reduced_data = MethodClass(n_components=2).fit_transform(da_stacked.values.T)\n",
        "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
        "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
        "    da = da_red.stack()\n",
        "\n",
        "    for sample in da.sample.values:\n",
        "        da_sample = da.sel(sample=sample)\n",
        "        ax.scatter(\n",
        "            da_sample.sel(pca_dim=0), da_sample.sel(pca_dim=1), label=sample, alpha=0.5\n",
        "        )\n",
        "    ax.set_title(titles[i])\n",
        "\n",
        "\n",
        "    i = i + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ZrvafoUtMMRB"
      },
      "outputs": [],
      "source": [
        "da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
        "da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
        "methods = [SpectralEmbedding, Isomap, PCA]\n",
        "titles = [\"SpectralEmbedding\", \"Isomap\", \"PCA\"]\n",
        "\n",
        "i = 0\n",
        "fig, axes = plt.subplots(1, len(methods), figsize=(len(methods) * 6, 6))\n",
        "\n",
        "while i < len(methods):\n",
        "    ax = axes[i]\n",
        "    MethodClass = methods[i]\n",
        "    if MethodClass == \"Isomap\":\n",
        "        reduced_data = MethodClass(n_components=1, p=1).fit_transform(\n",
        "            da_stacked.values.T\n",
        "        )\n",
        "    else:\n",
        "        reduced_data = MethodClass(n_components=2).fit_transform(da_stacked.values.T)\n",
        "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
        "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
        "    da = da_red.stack()\n",
        "    for sample in da.sample.values:\n",
        "        da_sample = da.sel(sample=sample)\n",
        "        ax.violinplot(\n",
        "            da_sample.sel(pca_dim=0),\n",
        "            #    alpha=0.5\n",
        "        )\n",
        "    #   ax.set_label(sample),\n",
        "    ax.set_title(titles[i])\n",
        "\n",
        "    # ax.legend()\n",
        "    i = i + 1\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYmReJ-nMMRB"
      },
      "source": [
        "# Adding noise\n",
        "\n",
        "What happens if we add noise to the synthetic data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr3RHGMSMMRC"
      },
      "outputs": [],
      "source": [
        "#\n",
        "def get_noise():\n",
        "    noise = np.random.random((512, 512))\n",
        "    noise = (noise - 0.5) * 4\n",
        "    return noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2_FFnLUMMRC"
      },
      "outputs": [],
      "source": [
        "\n",
        "x0 = np.sin(vals / 4) + get_noise()\n",
        "x1 = np.sin(vals / 2) + get_noise()\n",
        "x2 = np.sin(vals) + get_noise()\n",
        "x3 = np.sin(vals.T) + get_noise()\n",
        "x4 = np.sin(vals * 2) + get_noise()\n",
        "x5 = np.sin(vals * 3) + get_noise()\n",
        "\n",
        "wl_waves = [x0, x1, x2, x3, x4, x5]\n",
        "\n",
        "x_wavelength = torch.Tensor([[wave, wave, wave] for wave in wl_waves])\n",
        "\n",
        "da = pca_wavelength(x_wavelength)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNBigLndMMRC"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots(1, len(wl_waves), figsize=(3 * len(wl_waves), 4))\n",
        "i = 0\n",
        "while i < len(wl_waves):\n",
        "    ax[i].imshow(wl_waves[i])\n",
        "    ax[i].set_title(i)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8uIykqhMMRC"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots()\n",
        "cmap = matplotlib.cm.get_cmap(\"viridis\")\n",
        "for sample in da.sample.values:\n",
        "    da_sample = da.sel(sample=sample)\n",
        "    ax.scatter(\n",
        "        da_sample.sel(pca_dim=0),\n",
        "        da_sample.sel(pca_dim=1),\n",
        "        label=sample,\n",
        "        c=cmap(sample / 5),\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4BK7JSSMMRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_rot0 = rotate(x2, -90, mode=\"wrap\", reshape=False)\n",
        "x_rot1 = rotate(x2, -60, mode=\"wrap\", reshape=False)\n",
        "x_rot2 = rotate(x2, -30, mode=\"wrap\", reshape=False)\n",
        "x_rot3 = rotate(x2, 0, mode=\"wrap\", reshape=False)\n",
        "x_rot4 = rotate(x2, 35, mode=\"wrap\", reshape=False)\n",
        "x_rot5 = rotate(x2, 60, mode=\"wrap\", reshape=False)\n",
        "x_rot6 = rotate(x2, 90, mode=\"wrap\", reshape=False)\n",
        "\n",
        "rot_waves = [\n",
        "    x_rot0,\n",
        "    x_rot1,\n",
        "    x_rot2,\n",
        "    x_rot3,\n",
        "    x_rot4,\n",
        "    x_rot5,\n",
        "    x_rot6,\n",
        "]  # , x_rot7, x_rot8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjK8HO_HMMRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_rot = torch.Tensor([[wave, wave, wave] for wave in rot_waves])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeuOIc2fMMRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "out = model[0](x_rot).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T13:20:10.375863Z",
          "iopub.status.busy": "2022-06-15T13:20:10.375402Z",
          "iopub.status.idle": "2022-06-15T13:20:11.586743Z",
          "shell.execute_reply": "2022-06-15T13:20:11.585966Z",
          "shell.execute_reply.started": "2022-06-15T13:20:10.375802Z"
        },
        "id": "wme_ADqsMMRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots(1, len(rot_waves), figsize=(3 * len(rot_waves), 4))\n",
        "i = 0\n",
        "while i < len(rot_waves):\n",
        "    ax[i].imshow(rot_waves[i])\n",
        "    ax[i].set_title(i)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-15T13:20:12.3232Z",
          "iopub.status.busy": "2022-06-15T13:20:12.32044Z",
          "iopub.status.idle": "2022-06-15T13:20:12.957056Z",
          "shell.execute_reply": "2022-06-15T13:20:12.956286Z",
          "shell.execute_reply.started": "2022-06-15T13:20:12.323152Z"
        },
        "id": "aw_P893uMMRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "da_features = xr.DataArray(out, dims=(\"sample\", \"feature\", \"x\", \"y\"))\n",
        "da_stacked = da_features.stack(n=(\"sample\", \"x\", \"y\"))\n",
        "methods = [SpectralEmbedding, Isomap, PCA]\n",
        "titles = [\"SpectralEmbedding\", \"Isomap\", \"PCA\"]\n",
        "\n",
        "i = 0\n",
        "fig, axes = plt.subplots(1, len(methods), figsize=(len(methods) * 6, 6))\n",
        "\n",
        "while i < len(methods):\n",
        "    ax = axes[i]\n",
        "    MethodClass = methods[i]\n",
        "    if MethodClass == \"Isomap\":\n",
        "        reduced_data = MethodClass(n_components=1, p=1).fit_transform(\n",
        "            da_stacked.values.T\n",
        "        )\n",
        "    else:\n",
        "        reduced_data = MethodClass(n_components=2).fit_transform(da_stacked.values.T)\n",
        "    da_red_stacked = xr.DataArray(reduced_data, dims=(\"n\", \"pca_dim\"))\n",
        "    da_red = da_red_stacked.assign_coords(dict(n=da_stacked.n)).unstack()\n",
        "    da = da_red.stack()\n",
        "\n",
        "    for sample in da.sample.values:\n",
        "        da_sample = da.sel(sample=sample)\n",
        "        ax.scatter(\n",
        "            da_sample.sel(pca_dim=0), da_sample.sel(pca_dim=1), label=sample, alpha=0.5\n",
        "        )\n",
        "    ax.set_title(titles[i])\n",
        "\n",
        "\n",
        "    i = i + 1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}